# SEM V5.5 "Lean Crystal" - 4xA100 80GB Maximum Throughput
# Sweep-optimized params from 4xA100 cloud sweep (2026-02-08)
# bf16-mixed precision, DDP across 4 GPUs

model:
  hidden_dim: 256
  num_layers: 8
  vocab_size: 50262
  max_seq_length: 2048

encoder:
  sdr_sparsity: 16
  sdr_candidates: 128
  sinkhorn_epsilon: 0.07
  sinkhorn_max_iter: 15
  sinkhorn_tol: 1.0e-3
  sinkhorn_auto_epsilon: true
  sinkhorn_auto_epsilon_scale: 0.04
  soft_sparse: true
  soft_sparse_temp: 0.1
  simple_mode: true # SEOP Fix: Bypass Sinkhorn entirely for speed (direct embedding)

spinor:
  block_size: 8
  num_blocks: 32
  state_dim: 64
  mimo_groups: 8
  d_conv: 4

propagator:
  cayley_dt: 0.02
  num_layers: 1 # SEOP Fix: Decoupled from model depth (was 8)
  cg_max_iter: 5
  cg_tol: 1.0e-6
  nonlinear_alpha: 0.12
  laplacian_sparsity: 6
  lazy_cg: true
  lazy_cg_tol: 1.0e-6
  pit_gamma: 0.05
  use_chebyshev_kpm: true
  chebyshev_degree: 16

quantizer:
  codebook_size: 256
  group_size: 2
  fisher_ema_decay: 0.99
  outlier_percentile: 0.01
  dead_code_threshold: 100

sampler:
  temperature: 1.0
  top_k: 40
  top_p: 0.92
  min_p: 0.0
  typical_p: 0.92
  repetition_penalty: 1.43
  frequency_penalty: 0.0
  presence_penalty: 0.0
  no_repeat_ngram_size: 0
  top_a: 0.0
  epsilon_cutoff: 0.0
  eta_cutoff: 0.0
  temperature_last: false

training:
  batch_size: 2048
  micro_batch_size: 128 # SEOP Fix: Reduce accumulation steps (16 -> 4)
  gradient_checkpointing: true
  dtype: float32
  learning_rate: 8.6e-4
  weight_decay: 0.002
  encoder_lr_scale: 0.016
  warmup_steps: 500 # SEOP Fix: Reduced warmup to reach peak LR faster
  max_steps: 100000
  gradient_clip: 17.0
  unitary_lambda: 0.006
  unitary_clamp_min: 0.01
  unitary_clamp_max: 6.9
  label_smoothing: 0.058
  dataset_name: "HuggingFaceFW/fineweb-edu"
  tokenizer_path: "tokenizer/"
  num_workers: 8
  shuffle_buffer_size: 50000
  scheduler_type: "wsd"
  stable_steps: 0
  decay_steps: 10000
  lr_min_ratio: 0.1
  log_interval: 10 # SEOP Fix: Reduce logging frequency to save .item() syncs
  health_check_interval: 500
  checkpoint_interval: 200
  keep_checkpoints: 5
  wandb_project: "sem-v55-a100"
  wandb_enabled: true
  timing_enabled: true
  timing_log_interval: 1

v8:
  use_lindblad: true
  use_hybrid_automata: false # SEOP Fix: Disable to save 3 kernels/layer
  use_quaternionic: false
  use_mhc: true
  mhc_streams: 8
  mhc_num_iters: 1 # SEOP Fix: Reduce from 3 to 1 to save Sinkhorn passes
  mhc_tau: 0.031
  lindblad_gamma: 0.007
  num_lindblad_ops: 4
  curvature_threshold: 0.64
  condition_threshold: 62.0

curriculum:
  enabled: true
  stages:
    - min_score: 2
      seq_len: 1024
      min_steps: 20000
    - min_score: 3
      seq_len: 2048
      min_steps: 40000
    - min_score: 3
      seq_len: 2048
      min_steps: 40000

distillation:
  enabled: true
  alpha: 0.5
  ema_decay_start: 0.999
  ema_decay_end: 0.9999
  ema_decay_ramp_steps: 10000
  enable_at_stage: 1
  temperature: 2.0
