# SEM V5.5 "Lean Crystal" - Full Training Configuration
model:
  hidden_dim: 256
  num_layers: 8
  vocab_size: 32768
  max_seq_length: 2048

encoder:
  sdr_sparsity: 32
  sdr_candidates: 128
  sinkhorn_epsilon: 0.05
  sinkhorn_max_iter: 50
  sinkhorn_tol: 1.0e-3

spinor:
  block_size: 8
  num_blocks: 32
  state_dim: 64
  mimo_groups: 8
  d_conv: 4

propagator:
  cayley_dt: 0.1
  cg_max_iter: 20
  cg_tol: 1.0e-6
  nonlinear_alpha: 0.1
  laplacian_sparsity: 5

quantizer:
  codebook_size: 256
  group_size: 2
  fisher_ema_decay: 0.99
  outlier_percentile: 0.01
  dead_code_threshold: 100

sampler:
  temperature: 1.0
  top_k: 50
  top_p: 0.95

training:
  batch_size: 32
  micro_batch_size: 4
  learning_rate: 3.0e-4
  weight_decay: 0.01
  warmup_steps: 2000
  max_steps: 100000
  gradient_clip: 1.0
  gradient_checkpointing: false  # Disabled - causes tensor count mismatch bug

  # Data
  dataset_name: "HuggingFaceFW/fineweb-edu"
  tokenizer_path: "tokenizer/"
  num_workers: 4
  shuffle_buffer_size: 10000

  # Scheduler
  scheduler_type: "wsd"
  stable_steps: 0
  decay_steps: 5000
  lr_min_ratio: 0.1

  # Logging
  log_interval: 10
  health_check_interval: 100
  checkpoint_interval: 5000
  keep_checkpoints: 3

  # wandb
  wandb_project: "sem-v55-lean-crystal"
  wandb_enabled: true

curriculum:
  enabled: true
  stages:
    - min_score: 2
      seq_len: 512
      min_steps: 20000
    - min_score: 3
      seq_len: 1024
      min_steps: 30000
    - min_score: 3
      seq_len: 2048
      min_steps: 50000
  transition_check_interval: 500
  loss_plateau_threshold: 0.01
  loss_plateau_window: 1000
  lr_decay_per_stage: 0.7
  stage_warmup_steps: 500

distillation:
  enabled: true
  alpha: 0.7
  ema_decay_start: 0.999
  ema_decay_end: 0.9999
  ema_decay_ramp_steps: 10000
  enable_at_stage: 2
  temperature: 2.0
