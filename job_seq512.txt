WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
Fetching 107 files:   0%|          | 0/107 [00:00<?, ?it/s]Fetching 107 files:  18%|█▊        | 19/107 [00:00<00:00, 178.35it/s]Fetching 107 files:  35%|███▍      | 37/107 [00:00<00:00, 135.85it/s]Fetching 107 files:  71%|███████   | 76/107 [00:00<00:00, 229.11it/s]Fetching 107 files:  94%|█████████▍| 101/107 [00:00<00:00, 225.69it/s]Fetching 107 files: 100%|██████████| 107/107 [00:00<00:00, 189.80it/s]
14:16:53 [INFO] ============================================================
14:16:53 [INFO] SEM V5.5 Training - System Info
14:16:53 [INFO] ============================================================
14:16:53 [INFO] PyTorch: 2.6.0+cu124
14:16:53 [INFO] CUDA available: True
14:16:53 [INFO] CUDA version: 12.4
14:16:53 [INFO] GPU: NVIDIA L40S
14:16:53 [INFO] VRAM: 44.4GB
14:16:53 [INFO] SM count: 142
14:16:53 [INFO] bf16 supported: True
14:16:53 [INFO] CPU cores: 8
14:16:53 [INFO] ============================================================
14:16:53 [INFO] GPU: NVIDIA L40S (44.4GB)
14:16:53 [INFO] Device: cuda
14:16:53 [INFO] Config: configs/a100_optimized.yaml
14:16:53 [INFO] micro_batch=16, batch=512, accum=32
14:16:53 [INFO] DRY RUN: 20 steps, batch=32, seq=512, real streaming data, full timing
14:16:53 [INFO] Building SEM V5.5 model...
14:16:54 [INFO] Parameters: 27,542,120 effective real
14:16:54 [INFO] torch.compile disabled (--no-compile)
14:16:54 [INFO] AMP disabled (--no-amp)
14:16:54 [INFO] Gradient checkpointing enabled on 8 Mamba layers
14:16:54 [INFO] Model build time: 1.2s
14:16:54 [INFO] SEM V5.5 'Lean Crystal' Training
14:16:54 [INFO] Device: cuda
14:16:54 [INFO] Effective batch size: 32 (micro=4 x accum=8)
14:16:54 [INFO] [TRAIN] Building dataloader...
14:16:54 [INFO] [DATA] DataLoader created in 0.000s (batch_size=4, workers=4, pin_memory=True)
14:16:54 [INFO] [TRAIN] Creating data iterator...
14:16:54 [INFO] [TRAIN] Starting training loop (max_steps=20)...
14:16:54 [INFO] ============================================================
14:16:54 [INFO] [TRAIN] Loading first batch...
14:16:54 [INFO] [PACK] Starting sequence packing (seq_len=512)...
14:16:54 [INFO] [PACK] Starting sequence packing (seq_len=512)...
14:16:54 [INFO] [PACK] Starting sequence packing (seq_len=512)...
14:16:54 [INFO] [PACK] Starting sequence packing (seq_len=512)...
14:16:55 [INFO] [DATA] Starting FineWeb-Edu stream from HuggingFaceFW/fineweb-edu
14:16:55 [INFO] [DATA] Starting FineWeb-Edu stream from HuggingFaceFW/fineweb-edu
14:16:55 [INFO] [DATA] Split: train, min_score: 2
14:16:55 [INFO] [DATA] Split: train, min_score: 2
14:16:55 [INFO] [DATA] Using HF_TOKEN from environment
14:16:55 [INFO] [DATA] Using HF_TOKEN from environment
14:16:55 [INFO] [DATA] Starting FineWeb-Edu stream from HuggingFaceFW/fineweb-edu
14:16:55 [INFO] [DATA] Split: train, min_score: 2
14:16:55 [INFO] [DATA] Using HF_TOKEN from environment
14:16:55 [INFO] [DATA] Starting FineWeb-Edu stream from HuggingFaceFW/fineweb-edu
14:16:55 [INFO] [DATA] Split: train, min_score: 2
14:16:55 [INFO] [DATA] Using HF_TOKEN from environment
14:16:56 [INFO] [DATA] Dataset loaded in 0.91s
14:16:56 [INFO] [DATA] Filtering by min_score >= 2
14:16:56 [INFO] [DATA] Shuffling with buffer_size=50000
14:16:56 [INFO] [DATA] Pipeline setup: load=0.909s filter=0.001s shuffle=0.002s
14:16:56 [INFO] [DATA] Waiting for first document from stream...
14:16:56 [INFO] [DATA] Dataset loaded in 0.94s
14:16:56 [INFO] [DATA] Filtering by min_score >= 2
14:16:56 [INFO] [DATA] Shuffling with buffer_size=50000
14:16:56 [INFO] [DATA] Pipeline setup: load=0.938s filter=0.001s shuffle=0.002s
14:16:56 [INFO] [DATA] Waiting for first document from stream...
14:16:56 [INFO] [DATA] Dataset loaded in 1.03s
14:16:56 [INFO] [DATA] Filtering by min_score >= 2
14:16:56 [INFO] [DATA] Dataset loaded in 1.07s
14:16:56 [INFO] [DATA] Filtering by min_score >= 2
14:16:56 [INFO] [DATA] Shuffling with buffer_size=50000
14:16:56 [INFO] [DATA] Pipeline setup: load=1.073s filter=0.001s shuffle=0.002s
14:16:56 [INFO] [DATA] Waiting for first document from stream...
14:16:56 [INFO] [DATA] Shuffling with buffer_size=50000
14:16:56 [INFO] [DATA] Pipeline setup: load=1.029s filter=0.077s shuffle=0.002s
14:16:56 [INFO] [DATA] Waiting for first document from stream...
14:17:02 [INFO] [DATA] First doc received (5.6s)
14:17:02 [INFO] [DATA] First doc received (5.7s)
14:17:02 [INFO] [DATA] First doc received (6.1s)
14:17:03 [INFO] [DATA] First doc received (6.5s)
14:17:03 [INFO] [TRAIN] First batch loaded successfully!
14:17:38 [INFO] Step 1: | loss=10.9455 | lr=0.000000 | grad_norm=14.8470 | tok/s=378
14:18:10 [INFO] Step 2: | loss=10.9291 | lr=0.000001 | grad_norm=9.9798 | tok/s=509
14:18:42 [INFO] Step 3: | loss=10.9278 | lr=0.000001 | grad_norm=9.9541 | tok/s=509
14:19:15 [INFO] Step 4: | loss=10.9352 | lr=0.000001 | grad_norm=9.2830 | tok/s=506
14:19:47 [INFO] Step 5: | loss=10.9407 | lr=0.000001 | grad_norm=10.8044 | tok/s=511
14:19:47 [INFO]   Timing: total=32070.6ms | batch=0.2ms | xfer=0.1ms | fwd=1035.5ms | loss=0.0ms | bwd=2969.6ms | clip=6.4ms | fisher=6.3ms | opt=12.8ms
14:20:19 [INFO] Step 6: | loss=10.9390 | lr=0.000002 | grad_norm=9.8683 | tok/s=512
14:20:51 [INFO] Step 7: | loss=10.9368 | lr=0.000002 | grad_norm=10.1988 | tok/s=511
14:21:23 [INFO] Step 8: | loss=10.9043 | lr=0.000002 | grad_norm=8.7665 | tok/s=514
